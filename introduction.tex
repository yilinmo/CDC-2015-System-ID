\section{Introduction}
Cyber-Physical Systems (CPSs) refer to the embedding of widespread sensing, networking, computation, and control into physical spaces with the goal of making them safer, more efficient and reliable. Driven by the miniaturization and integration of sensing, communication, and computation in cost effective devices, CPSs are bound to transform several industries such as aerospace, transportation, built environment, energy, health-care, and manufacturing, to name a few. While the use of dedicated communication networks has so far sheltered systems from the outside world, use of off-the-shelf networking and computing, combined with unattended operation of a plethora of devices, provides several opportunities for malicious entities to inject attacks on CPSs. A wide variety of motivations exist for launching an attack on CPSs, ranging from economic reasons such as drawing a financial gain, all the way to terrorism. Any attack on safety-critical CPSs may significantly hamper the economy and lead to the loss of human lives. While the threat of attacks on CPSs tends to be underplayed at times, the Stuxnet worm provided a clear sample of the future to come~\cite{Chen2010,Fidler2011}.

A substantial amount of research effort has been dedicated to identifying possible security vulnerabilities of the CPS and develop countermeasures. To this end, many attack models, such as stealthy attack\footnote{The stealthy attack is also referred to as false data injection attack, zero dynamics attack in the literature.}~\cite{Liu2009,Sundaram2011,Pasqualetti2013,Fawzi2014,Teixeira2015a}, replay attack~\cite{Mo2014,Mo2015} and covert attack~\cite{Smith2011}, have been proposed by various researchers. Teixeira et al.~\cite{Teixeira2015} propose a characterization of different attack models based on the attacker's resources, which are divided into three different categories: knowledge of the system model, knowledge of the real-time control and sensory data (disclosure resources) and the capability to modify the control and sensory data (disruptive resources). Their results illustrate that many attack models proposed in the literature require the knowledge of the system models from the adversary. For example, in the stealthy attack scenario~\cite{Pasqualetti2013}, the adversary will inject an external control input to the physical system and then remove the physical system's response to this malicious input from the sensors' measurements. The system operator will not be able to detect the attack if the response to the malicious control input is removed perfectly. However, such an attack requires the adversary to know the perfect model of the physical system, which may be difficult to acquire in many practical scenarios, since the modeling information is usually stored inside the controller. On the other hand, we argue that in many situations, the control and sensory data are much easier to acquire. This is due to the fact that these data are typically not encrypted for many CPSs~\cite{Koscher2010}. Furthermore, even if the control and sensory data are encrypted, it might be easier to break the security of sensors and actuators due to their low computational capability. Thus, for the adversary, the disclosure resources may be more available than the model knowledge.

In this paper, we discuss whether the adversary can use its disclosure resources to gain the model knowledge by the means of system identification. We model the CPS as a linear feedback control system, which is illustrated in Fig~\ref{fig:feedback}. The adversary is assumed to \emph{only use} its disclosure resources. In other words, it can only passively observe the control input $u$ and the sensory data $y$ and cannot inject any disturbances to the system. The goal of the adversary is to learn the physical system model $\mathcal G(z)$, which further enables the adversary to launch other attacks, such as stealthy attack and covert attack.
Such an attack model is very similar to the Known-Plaintext Attack (KPA) studied in information security, where the adversary has samples of both the plaintext and the corresponding ciphertext and want to deduce the encryption key. For our case, one can view the system model, the control input $u$ and the sensory data $y$ as the encryption key, plaintext and ciphertext respectively. 

%
%It is worth mentioning that with additional disruptive resources, the adversary can also launch a more powerful Chosen-Plaintext Attack (CPA), where it can actively modify the control input $u$ and observe the corresponding system output $y$. However, if the attacker changes the control input $u$ carelessly, it may result in a substantial change in the sensor measurement $y$, which could enable the system to detect the presence of the malicious third party. If the stealthiness of the attack is of concern to the attacker, then a reasonable strategy of the adversary is to first launch a passive KPA without risking being detected. After a coarse system model is learned, the attacker can then design a stealthy control input $u$ to identify a more accurate model. In such a scenario, the KPA is the first step for the adversary to gain model knowledge.

%In Computer Science, there are three types of attack models as listed below. Imagine in the feedback control context, the plant text can be thought as the input of the system while the cipher text output. We shall refer to the corresponding analogy in systems theory.

%{\bf Known-plaintext attack:} it is assumed that pairs of plaintext and the corresponding enciphered text are available to the analyst. %During World War II, the Allies used known-plaintexts in their successful cryptanalysis of the Enigma machine cipher. The plaintext samples are called ``cribs''; the term originated at Bletchley Park, the British World War II decryption operation.

% In the system and control theory, consider a feedback configuration in Fig.~\ref{fig:feedback}, this kind of attack can be modelled as only the output is available to the attacker.

%{\bf Ciphertext-only attack:} it is assumed that only the cipher text is available to the attacker.  In the noiseless case, Yuan et. al. \cite{yeautomatica, yeACC} proposed an algorithm that can predict the future output by using historical values of $y$. 

%{\bf Chosen-plaintext attack:} in this scenario, the attacker is able to choose a number of plaintexts to be enciphered and have access to the resulting ciphertext. This corresponds to the experimental design in system identification. 

As a result, we will focus on KPA in this paper. The main contributions of the paper are twofold:
\begin{enumerate}
  \item We provide a necessary condition and a sufficient condition, under which the system is vulnerable to KPA, i.e., the adversary can successfully identify the system model $\mathcal G(z)$. The results can be viewed as an application of classical system identification \cite{anderson1, anderson2, anderson3, Ljung, keith, anderson} for the closed-loop system described in Section~\ref{sec:sysid}.  

  \item We design a countermeasure to KPA by using a ``low-rank'' controller design strategy for $\mK(z)$ while trading off the $LQG$ control performance.
\end{enumerate}

%\begin{itemize}
%  \item Attacker model has been introduced  the 
%  \item Comparing to existed literature in cyber-physical systems theory, 
%    \Ye{cite others' work in assuming knowing $\mG$} this paper can obtain $\mG$ with theoretical guarantee from data. This furthermore provides a  
%  \item Design tradeoff between the performance of feedback controller versus security consideration has been investigated. 
%  \item This also adds new results to the system identification community that 
%\end{itemize}

The rest of the paper is organized as follows: In Section~\ref{sec:model}, we model the system as a linear feedback control system subject to Gaussian process and measurement noise. In Section~\ref{sec:sysid}, we provide necessary and sufficient conditions, under which the adversary can identify the system model $\mathcal G(z)$. We further provide a numerical algorithm for the adversary to compute $\mathcal G(z)$. In Section~\ref{sec:countermeasure}, we present a controller design which is resilient to KPA while only incurring minimal control performance loss. 

